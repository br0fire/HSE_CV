{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJNzsZgrYKrC"
      },
      "source": [
        "# Диффузионные модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcYKVwBzYMyD"
      },
      "source": [
        "## Домашнее задание [10 баллов]. Latent Diffusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xn9VUvIYO0H"
      },
      "source": [
        "### Введение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4lEbApC725T"
      },
      "source": [
        "На семинаре Вы познакомились с тем, как диффузионная модель реализуется на практике. А именно, мы рассмотрели базовую диффузионную модель DDPM из [(Ho et al., 2020)](https://arxiv.org/abs/2006.11239), в которой скрытые переменные есть те же изображений, но зашумленные. Такой подход на практике уже давно никто не использует, потому что он является очень вычислительно затратным. Вместо этого обычно рассматриваются скрытые переменные из латентного пространства какого-нибудь автоэнкодера - обычно, VQ-VAE [(Oord et al., 2017)](https://arxiv.org/abs/1711.00937), как в Stable Diffusion [(Rombach et al., 2021)](https://arxiv.org/abs/2112.10752). Подробнее про этот подход Вы можете прочесть в Модификациях диффузионных моделях, однако здесь мы приведем схематично его принцип работы. Итак, Latent Diffusion включает в себя следующие стадии:\n",
        "\n",
        "1) Изображение пропускается через энкодер, благодаря чему получается его скрытое представление;\n",
        "\n",
        "2) Уже в латентном пространстве обучается диффузионная модель для предсказания шума, добавляемого к скрытым переменным;\n",
        "\n",
        "3) Полученное скрытое представление пропускается через декодер, вследствие чего создается новое изображение."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wliWYTonYQo2"
      },
      "source": [
        "### Цель домашнего задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w6tVh8X9nrc"
      },
      "source": [
        "1) Реализовать модель Latent Diffusion для безусловной генерации RGB изображений;\n",
        "\n",
        "2) Обучить модель на [датасете](https://huggingface.co/datasets/nelorth/oxford-flowers) с изображениями цветов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtkdTHC8UrUp"
      },
      "source": [
        "### Импортирование библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:26:14.850457Z",
          "iopub.status.busy": "2024-04-26T07:26:14.849425Z",
          "iopub.status.idle": "2024-04-26T07:26:20.701403Z",
          "shell.execute_reply": "2024-04-26T07:26:20.700626Z",
          "shell.execute_reply.started": "2024-04-26T07:26:14.850423Z"
        },
        "id": "Db5Yrew7CnXe",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "from typing import List, Tuple, Optional\n",
        "from copy import deepcopy\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if USE_CUDA else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObVBqygJDMsY"
      },
      "source": [
        "### Датасет"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rNPfhK2DOAI"
      },
      "source": [
        "Посмотрим на данные, с которыми нам предстоит иметь дело.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:26:20.704122Z",
          "iopub.status.busy": "2024-04-26T07:26:20.703066Z",
          "iopub.status.idle": "2024-04-26T07:26:35.035712Z",
          "shell.execute_reply": "2024-04-26T07:26:35.034278Z",
          "shell.execute_reply.started": "2024-04-26T07:26:20.704085Z"
        },
        "id": "LZT84trORFnw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#!pip install -q datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:26:35.037733Z",
          "iopub.status.busy": "2024-04-26T07:26:35.037382Z",
          "iopub.status.idle": "2024-04-26T07:26:47.989736Z",
          "shell.execute_reply": "2024-04-26T07:26:47.988746Z",
          "shell.execute_reply.started": "2024-04-26T07:26:35.037701Z"
        },
        "id": "uL1Ku8g6DYgA",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6bbfaa72a8b42ab9986a06e72ac072e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deacb71aa670423d97f93c2f2b135c27",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-12de94e121bdbead.parquet:   0%|          | 0.00/303M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a723867fec244e5a72103400be13391",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-96eeec628415add6.parquet:   0%|          | 0.00/43.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1b6f9d4e2914a47b2e18478796cbad8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/7169 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85618a4a0b9e41799d7272dc2c10e548",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1020 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"nelorth/oxford-flowers\", split='train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNDqhfCzbIp"
      },
      "source": [
        "Для ускорения процесса обучения мы отберем топ-3 самых часто встречающихся классов цветков."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:26:47.993020Z",
          "iopub.status.busy": "2024-04-26T07:26:47.992339Z",
          "iopub.status.idle": "2024-04-26T07:27:02.610061Z",
          "shell.execute_reply": "2024-04-26T07:27:02.609167Z",
          "shell.execute_reply.started": "2024-04-26T07:26:47.992992Z"
        },
        "id": "TRtpXwePzbIp",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "k = 3\n",
        "labels_selected = [x[0] for x in Counter(dataset['label']).most_common()[:k]]\n",
        "print(f'Top-3 labels: {labels_selected}')\n",
        "dataset = dataset.filter(lambda example: example['label'] in labels_selected)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:02.611568Z",
          "iopub.status.busy": "2024-04-26T07:27:02.611252Z",
          "iopub.status.idle": "2024-04-26T07:27:03.598629Z",
          "shell.execute_reply": "2024-04-26T07:27:03.597684Z",
          "shell.execute_reply.started": "2024-04-26T07:27:02.611513Z"
        },
        "id": "4Qmshn65EECu",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 4, figsize=(20, 4))\n",
        "\n",
        "for i, image in enumerate(dataset[:4]['image']):\n",
        "    axs[i].imshow(image)\n",
        "    axs[i].set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVFEnaU7EpvO"
      },
      "source": [
        "Изображения все разного размера, поэтому Вам необходимо сначала предобработать их:\n",
        "- `Resize` изменяет размер изображения до `(IMAGE_SIZE, IMAGE_SIZE)`;\n",
        "- `RandomHorizontalFlip` аугментирует датасет с помощью случайных отражений изображений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:03.600317Z",
          "iopub.status.busy": "2024-04-26T07:27:03.599947Z",
          "iopub.status.idle": "2024-04-26T07:27:03.604499Z",
          "shell.execute_reply": "2024-04-26T07:27:03.603532Z",
          "shell.execute_reply.started": "2024-04-26T07:27:03.600290Z"
        },
        "id": "fKCGUFPVFgAE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:03.606238Z",
          "iopub.status.busy": "2024-04-26T07:27:03.605910Z",
          "iopub.status.idle": "2024-04-26T07:27:03.614024Z",
          "shell.execute_reply": "2024-04-26T07:27:03.612908Z",
          "shell.execute_reply.started": "2024-04-26T07:27:03.606197Z"
        },
        "id": "dALjSl2tFTNh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "preprocess = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvNSUtutFezJ"
      },
      "source": [
        "Мы будем использовать метод `set_transform` из [🤗 Datasets](https://huggingface.co/docs/datasets), чтобы применять преобразования непосредственно во время обучения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:03.615702Z",
          "iopub.status.busy": "2024-04-26T07:27:03.615387Z",
          "iopub.status.idle": "2024-04-26T07:27:03.627772Z",
          "shell.execute_reply": "2024-04-26T07:27:03.626824Z",
          "shell.execute_reply.started": "2024-04-26T07:27:03.615676Z"
        },
        "id": "H2CZxqkhFvep",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def transform(examples):\n",
        "    images = [preprocess(image.convert(\"RGB\")) for image in examples[\"image\"]]\n",
        "    return {\"images\": images}\n",
        "\n",
        "dataset.set_transform(transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4Xy3SoFBTCp"
      },
      "source": [
        "### Автокодировщик"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9ZbxzAiBcgT"
      },
      "source": [
        "Обучать автокодировщик для создания латентного представления изображений - очень сложная и долгая задача, требующая серьезных вычислительных мощностей. Поэтому мы предлагаем воспользоваться уже предобученной моделью [VQ-VAE](https://huggingface.co/docs/diffusers/api/models/autoencoderkl) от Stable Diffusion из библиотеки [🤗 Diffusers](https://huggingface.co/docs/diffusers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:03.629336Z",
          "iopub.status.busy": "2024-04-26T07:27:03.629028Z",
          "iopub.status.idle": "2024-04-26T07:27:17.568795Z",
          "shell.execute_reply": "2024-04-26T07:27:17.567665Z",
          "shell.execute_reply.started": "2024-04-26T07:27:03.629311Z"
        },
        "id": "V-9A998fAZP0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q -U diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:17.573447Z",
          "iopub.status.busy": "2024-04-26T07:27:17.573119Z",
          "iopub.status.idle": "2024-04-26T07:27:18.681423Z",
          "shell.execute_reply": "2024-04-26T07:27:18.680531Z",
          "shell.execute_reply.started": "2024-04-26T07:27:17.573416Z"
        },
        "id": "YgjWJoMCCF7N",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from diffusers import AutoencoderKL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:18.682986Z",
          "iopub.status.busy": "2024-04-26T07:27:18.682676Z",
          "iopub.status.idle": "2024-04-26T07:27:26.492322Z",
          "shell.execute_reply": "2024-04-26T07:27:26.491327Z",
          "shell.execute_reply.started": "2024-04-26T07:27:18.682957Z"
        },
        "id": "pqE3yCUaBvts",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
        "vae = vae.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJxTArBkAv3G"
      },
      "source": [
        "### Диффузионная модель [9 баллов]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX5l2lP8Axe7"
      },
      "source": [
        "В отличие от семинара, где мы реализовывали модель U-Net для предсказания шума с нуля, здесь мы воспользуемся уже готовой [имплементацией Фила Ванга](https://github.com/lucidrains/denoising-diffusion-pytorch) и далее сконцентрируемся только на прямом и обратном диффузионных процессах.\n",
        "\n",
        "Ниже Вы можете видеть вспомогательную функцию, которая преобразует число в тензор. Например, если необходимо создать тензор размера `broadcast_shape` из одного и того же числа, находящегося по индексу `index` в списке `array`. Посмотрите внимательно на этот код, Вам предстоит использовать его в большинстве методов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:26.494068Z",
          "iopub.status.busy": "2024-04-26T07:27:26.493731Z",
          "iopub.status.idle": "2024-04-26T07:27:26.500445Z",
          "shell.execute_reply": "2024-04-26T07:27:26.499561Z",
          "shell.execute_reply.started": "2024-04-26T07:27:26.494041Z"
        },
        "id": "0VwXNzi6fQZm",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def _extract_into_tensor(arr, indices, broadcast_shape):\n",
        "    \"\"\"\n",
        "    Извлекает значения из одномерного torch tensor для батча индексов.\n",
        "    :param arr: одномерный torch tensor.\n",
        "    :param indices: тензор индексов, извлекаемых из arr.\n",
        "    :param broadcast_shape: бОльший shape из K размерностей с размерностью батча,\n",
        "                            равной длине indices.\n",
        "    :return: тензор размерностей [batch_size, 1, ...], где shape имеет K размерностей.\n",
        "    \"\"\"\n",
        "    assert len(arr.shape) == 1\n",
        "    res = arr.to(device=indices.device)[indices].float()\n",
        "    while len(res.shape) < len(broadcast_shape):\n",
        "        res = res[..., None]\n",
        "    return res.expand(broadcast_shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5nFAYm4EDvH"
      },
      "source": [
        "#### Forward Diffusion [3 балла]\n",
        "\n",
        "Давайте начнем с прямого диффузионного процесса. Вспомним основную теорию, которая пригодится в реализации диффузионной модели.\n",
        "\n",
        "**Forward process** определяется как апостериорное распределение $q(\\mathbf{x}_{1:T}|\\mathbf{x}_0)$.\n",
        "\n",
        "Это марковская цепь, которая последовательно добавляет гауссовский шум к исходному объекту $\\mathbf{x}_0$.\n",
        "\n",
        "На каждом шаге этого процесса гауссовский шум добавляется с разной магнитудой, которая определяется расписанием дисперсий $\\{\\beta_1, ... \\beta_T\\}$.\n",
        "Если это расписание правильно выбрано, а $T$ стремится к бесконечности (или просто достаточно велико), мы будем сходиться к случайному шуму $\\mathcal{N}(0, I)$.\n",
        "\n",
        "Марковская цепь определяется как:\n",
        "$$\n",
        " q(\\mathbf{x}_t | \\mathbf{x}_{t - 1}) := \\mathcal{N}(\\mathbf{x}_t | \\sqrt{1 - \\beta_t}\\mathbf{x}_{t - 1}, \\beta_tI), \\ \\ \\ \\ \\ \\ \\ q(\\mathbf{x}_{1:T}|\\mathbf{x}_0) = \\prod_{t = 1}^T q(\\mathbf{x}_t | \\mathbf{x}_{t - 1})\n",
        "$$\n",
        "\n",
        "Чтобы получить $\\mathbf{x}_t$, нам необходимо вычислять $\\mathbf{x}_1, ..., \\mathbf{x}_{t - 1}$ итеративно.\n",
        "\n",
        "К счастью, благодаря свойствам нормального распределения, мы можем сделать это более эффективно.\n",
        "\n",
        "Обозначим\n",
        "$\\alpha_t = 1- \\beta_t$ и $\\bar{\\alpha}_t= \\prod_{s = 1}^t\\alpha_s$.\n",
        "Тогда\n",
        "$$\n",
        "q(\\mathbf{x}_t | \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_t|\\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1-\\bar{\\alpha}_t) \\mathbf{I}).\n",
        "\\tag{1}\n",
        "$$\n",
        "\n",
        "\n",
        "Так мы можем получить очень полезное выражение\n",
        "$$\n",
        "    \\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1-\\bar{\\alpha}_t} \\cdot \\boldsymbol{\\epsilon}. \\tag{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xD0JM0rEDvI"
      },
      "source": [
        "Создадим базовый класс для диффузии (мы будем использовать его для прямого и обратного процессов)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLdGjqG-F9wj"
      },
      "outputs": [],
      "source": [
        "class BaseDiffusion:\n",
        "    def __init__(self, num_timesteps: int):\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.betas = self._get_beta_schedule(num_timesteps)\n",
        "        self.alphas = 1 - self.betas\n",
        "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jydnsc3F-n_"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 1 [1 балл]**\n",
        "\n",
        "При инициализации класса `BaseDiffusion` мы создаем расписание дисперсий `betas`. Вам необходимо написать метод `_get_beta_schedule`, который используется для этого. Он должен возвращать `np.ndarray` под названием `betas`, который будет иметь длину `num_diffusion_steps` и содержать значения `beta` от `beta_start` до `beta_end` в порядке возрастания. Для совместимости с `PyTorch` укажите при создании `dtype=np.float64`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:26.501827Z",
          "iopub.status.busy": "2024-04-26T07:27:26.501519Z",
          "iopub.status.idle": "2024-04-26T07:27:26.555780Z",
          "shell.execute_reply": "2024-04-26T07:27:26.554935Z",
          "shell.execute_reply.started": "2024-04-26T07:27:26.501800Z"
        },
        "id": "PRUh2GlcEDvI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def _get_beta_schedule(self, num_diffusion_timesteps):\n",
        "    assert num_diffusion_timesteps >= 20\n",
        "    scale = 1000 / num_diffusion_timesteps\n",
        "    beta_start = scale * 0.0001\n",
        "    beta_end = scale * 0.02\n",
        "    # ====\n",
        "    # 1. Ваш код\n",
        "    # Создайте np.ndarray, содержащий num_diffusion_steps значений beta\n",
        "    # от beta_start до beta_end в порядке возрастания, укажите dtype=np.float64\n",
        "    betas = ...\n",
        "    # ====\n",
        "    assert len(betas.shape) == 1, \"betas must be 1-D\"\n",
        "    assert (betas > 0).all() and (betas <= 1).all()\n",
        "    betas = torch.from_numpy(betas).double()\n",
        "    return betas\n",
        "\n",
        "BaseDiffusion._get_beta_schedule = _get_beta_schedule\n",
        "\n",
        "basediff = BaseDiffusion(num_timesteps=20)\n",
        "basediff.betas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hExeOMnCHZ_n"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Muw-oEfjbCE"
      },
      "source": [
        "Мы готовы определить прямой диффузионный процесс. У него будет два метода:\n",
        "- чтобы получить среднее и дисперсию распределения $q(\\mathbf{x}_t | \\mathbf{x}_0)$,\n",
        "- чтобы сгенерировать сэмплы из этого распределения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6ytm4GnHLcg"
      },
      "outputs": [],
      "source": [
        "class ForwardDiffusion(BaseDiffusion):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xyh_vJYGHNQ_"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 2 [1 балл]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U42TGfSHRtB"
      },
      "source": [
        "От Вас требуется реализовать метод `get_mean_variance` класса `ForwardDiffusion`. Его суть заключается в том, чтобы по известному исходному `x0` и моменту времени `t` вычислить математическое ожидание и дисперсию распределения $q(\\mathbf{x}_t | \\mathbf{x}_0)$. Метод должен возвращать два `torch.tensor`, первый из которых, `mean`, содержит среднее значение искомого распределения, а второй, `variance`, содержит, соответственно, дисперсию. Используйте уравнение (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBPxtTzcJ8fY"
      },
      "outputs": [],
      "source": [
        "def get_mean_variance(self, x0, t):\n",
        "    # ====\n",
        "    # 2. Ваш код\n",
        "    # Вычислите среднее и дисперсию распределения q(x_t | x_0) (используйте уравнение (1))\n",
        "    # Подсказка: Используйте функцию `_extract_into_tensor`\n",
        "    sqrt_alphas_cumprod = self.alphas_cumprod.sqrt()\n",
        "    mean = ...\n",
        "    variance = ...\n",
        "    # ====\n",
        "    return mean, variance\n",
        "\n",
        "ForwardDiffusion.get_mean_variance = get_mean_variance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7Y_eG7DKWRt"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r9Mbhw3KjSr"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 3 [1 балл]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fq_klRAAKxRE"
      },
      "source": [
        "Вам необходимо реализовать метод `get_samples`. Ему на вход подаются исходный тензор `x0`, момент времени `t`, а также шум `noise`, то есть $\\boldsymbol{\\epsilon}$ в наших обозначениях. Метод должен генерировать сэмпл `samples` из распределения $q(\\mathbf{x}_t | \\mathbf{x}_0)$. Для этого нужно получить `mean` и `variance` с помощью метода `get_mean_variance`, а затем использовать их, а также шум `noise`, чтобы получить $\\mathbf{x}_t$ из $\\mathbf{x}_0$. Используйте уравнение (2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1Jvdk_xKtJX"
      },
      "outputs": [],
      "source": [
        "def get_samples(self, x0, t, noise=None):\n",
        "    if noise is None:\n",
        "        noise = torch.randn_like(x0)\n",
        "    # ====\n",
        "    # 3. Ваш код\n",
        "    # Сгенерируйте сэмпл из распределения q(x_t | x_0) (используйте уравнение (2))\n",
        "    samples = ...\n",
        "    # ====\n",
        "    return samples\n",
        "\n",
        "ForwardDiffusion.get_samples = get_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tETLFZl3Mpjp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:26.557012Z",
          "iopub.status.busy": "2024-04-26T07:27:26.556751Z",
          "iopub.status.idle": "2024-04-26T07:27:26.609941Z",
          "shell.execute_reply": "2024-04-26T07:27:26.609122Z",
          "shell.execute_reply.started": "2024-04-26T07:27:26.556989Z"
        },
        "id": "S3X5Gm1aC3zc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Тестирование Вашего кода\n",
        "def test_forward_diffusion():\n",
        "    fdiff = ForwardDiffusion(num_timesteps=100)\n",
        "    SHAPE = [2, 20]\n",
        "    x0 = torch.ones(SHAPE)\n",
        "    t = torch.ones((2,)).long() * 5\n",
        "    mean, variance = fdiff.get_mean_variance(x0=x0, t=t)\n",
        "    assert list(mean.shape) == SHAPE\n",
        "    assert list(variance.shape) == SHAPE\n",
        "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9820154)\n",
        "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.03564582)\n",
        "\n",
        "    xt = fdiff.get_samples(x0=x0, t=t)\n",
        "    assert list(xt.shape) == SHAPE\n",
        "\n",
        "    noise = torch.ones(SHAPE)\n",
        "    xt = fdiff.get_samples(x0=x0, t=t, noise=noise)\n",
        "    assert np.allclose(xt.numpy(), np.ones(SHAPE) * 1.1708164)\n",
        "    print('Отлично, Вы справились!')\n",
        "\n",
        "test_forward_diffusion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKScfUPwEDvI"
      },
      "source": [
        "#### Reverse Diffusion [4 балла]\n",
        "\n",
        "**Reverse process** последовательно расшумляет чистый гауссовский шум $\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$, пока мы не получим объект из исходного распределения $q(\\mathbf{x})$.\n",
        "\n",
        "Это вероятностная модель с латентными переменными\n",
        "$p(\\mathbf{x}_0 | \\boldsymbol{\\theta}) := \\int p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta}) d\\mathbf{x}_{1:T}$,\n",
        "где\n",
        "- скрытые переменные $\\mathbf{z} = \\{\\mathbf{x}_1, ..., \\mathbf{x}_T \\}$ соответствуют зашумленным объектам,\n",
        "- $\\mathbf{x}_0$ есть объект из исходного распределения $q(\\mathbf{x})$.\n",
        "\n",
        "\n",
        "Совместное распределение $p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta})$ называется обратным диффузионным процессом, который по существу есть Марковская цепь с гауссовскими распределениями $p(\\mathbf{x}_{i-1}|\\mathbf{x}_{i}, \\boldsymbol{\\theta})$:\n",
        "$$\n",
        "p(\\mathbf{x}_{0:T} | \\boldsymbol{\\theta}) = p(\\mathbf{x}_T | \\boldsymbol{\\theta}) \\prod_{t = 1}^T p(\\mathbf{x}_{t-1}|\\mathbf{x}_t, \\boldsymbol{\\theta}), \\quad p(\\mathbf{x}_{T} | \\boldsymbol{\\theta}) = p(\\mathbf{x}_{T}) = \\mathcal{N}(\\mathbf{x}_T | 0, \\mathbf{I})\n",
        "$$\n",
        "$$\n",
        "  p(\\mathbf{x}_{t - 1}|\\mathbf{x}_t, \\boldsymbol{\\theta}) = \\mathcal{N}(\\mathbf{x}_{t - 1}| \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)). \\tag{3}\n",
        "$$\n",
        "\n",
        "Мы с Вами уже обсуждали, как получается нижняя вариационная оценка ELBO для такой модели:\n",
        "\n",
        "$$\n",
        "    \\mathcal{L}(q, \\boldsymbol{\\theta}) =  \\mathbb{E}_{q} \\Bigl[\\log p(\\mathbf{x}_0 | \\mathbf{x}_1, \\boldsymbol{\\theta}) - KL\\bigl(q(\\mathbf{x}_T | \\mathbf{x}_0) || p(\\mathbf{x}_T)\\bigr)\n",
        "    - \\sum_{t=2}^T \\underbrace{KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr)}_{\\mathcal{L}_t} \\Bigr].\n",
        "$$\n",
        "\n",
        "Здесь мы используем следующее распределение $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\mathbf{x}_{t-1}; \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0), \\tilde{\\beta}_t \\mathbf{I}) $, где\n",
        "$$\n",
        "\\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{\\sqrt{\\alpha_t}(1 - \\bar{\\alpha}_{t-1})}{1 - \\bar{\\alpha}_t} \\mathbf{x}_t + \\frac{\\sqrt{\\bar{\\alpha}_{t-1}}\\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}_0\n",
        "\\tag{4}\n",
        "$$\n",
        "$$\n",
        "\\tilde{\\beta}_t = \\frac{1 - \\bar{\\alpha}_{t-1}}{1 - \\bar{\\alpha}_t} \\cdot \\beta_t\n",
        "\\tag{5}\n",
        "$$\n",
        "\n",
        "Эти страшные формулы на самом деле несложно вывести. Если интересно, больше деталей можете найти в оригинальной статье [Denoising Diffusion Probabilistic Models (Ho et al., 2020)](https://arxiv.org/abs/2006.11239).\n",
        "\n",
        "Наша текущая цель состоит в определении параметров $\\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t), \\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)$ обратного процесса.\n",
        "\n",
        "##### Дисперсия\n",
        "Наше первое предположение состоит в том, чтобы положить дисперсию равной $\\boldsymbol{\\sigma}^2_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) = \\tilde{\\beta}_t$. Это, на самом деле, очень естественное требование, поскольку нам хочется предсказывать в основном именно среднее значение.\n",
        "\n",
        "##### Математическое ожидание\n",
        "Здесь мы будем использовать выражение (2), чтобы получить $\\mathbf{x}_0$ из $\\mathbf{x}_t$:\n",
        "$$\n",
        "    \\mathbf{x}_0 = \\frac{\\mathbf{x}_t - \\sqrt{1 - \\bar{\\alpha}_{t}} \\cdot \\boldsymbol{\\epsilon}}{\\sqrt{\\bar{\\alpha}_{t}}}.\n",
        "    \\tag{6}\n",
        "$$\n",
        "\n",
        "Если мы подставим это выражение в формулу (4), то получим:\n",
        "$$\n",
        "    \\boldsymbol{\\mu}(\\mathbf{x}_t, \\mathbf{x}_0) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon} \\right).\n",
        "$$\n",
        "\n",
        "В целом, идея состоит в параметризации среднего значения нашей модели в таком же виде:\n",
        "$$\n",
        "    \\boldsymbol{\\mu}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( \\mathbf{x}_t - \\frac{1 - \\alpha_t}{\\sqrt{1 - \\bar{\\alpha}_t}} \\cdot \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) \\right).\n",
        "$$\n",
        "\n",
        "\n",
        "**Замечание**: наша модель предсказывает шум, который добавляется к $\\mathbf{x}_0$, чтобы получить $\\mathbf{x}_t$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMdOXLa3M5JK"
      },
      "source": [
        "Перейдем к реализации обратного диффузионного процесса в коде. Для этого создадим класс `ReverseDiffusion`, унаследованный от `BaseDiffusion`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8LU8Yvojvvd"
      },
      "outputs": [],
      "source": [
        "class ReverseDiffusionTemplate(BaseDiffusion):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.alphas_cumprod_prev = torch.cat(\n",
        "            [torch.tensor([1.0], device=self.betas.device), self.alphas_cumprod[:-1]], dim=0\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxC01ZjvlLgp"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 4 [1 балл]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKFbLyMKlVHf"
      },
      "source": [
        "От Вас требуется написать функцию `get_variances`, которая будет использоваться для того, чтобы определить дисперсии для обратного диффузионного процесса $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0)$. Используйте уравнение (5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG-0URadjwfV"
      },
      "outputs": [],
      "source": [
        "def get_variances(self):\n",
        "    # ====\n",
        "    # 4. Ваш код\n",
        "    # Вычислите дисперсию распределения q(x_{t-1} | x_t, x_0) (используйте уравнение (5))\n",
        "    variance = ...\n",
        "    # ====\n",
        "    # Первое значение ноль, но далее мы будем брать логарифм от выражения, поэтому заменим его на второе значение\n",
        "    self.variance_clipped = torch.cat([variance[1:2], variance[1:]], dim=0)\n",
        "\n",
        "ReverseDiffusionTemplate.get_variances = get_variances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVV0sm_KlRHU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS9WXeXNm-sp"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 5 [1 балл]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEHz6YyFnUsc"
      },
      "source": [
        "Подсчет дисперсии реализован. Теперь займемся математическим ожиданием. В следующей функции `get_coeffs` Вам необходимо вычислить коэффициенты, которые возникают перед $\\mathbf{x}_t$ и $\\mathbf{x}_0$ в формуле для среднего. Используйте уравнение (4)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlgrmPsPksFp"
      },
      "outputs": [],
      "source": [
        "def get_coeffs(self):\n",
        "    # ====\n",
        "    # 5. Ваш код\n",
        "    # Вычислите коэффициенты перед слагаемыми в распределении q(x_{t-1} | x_t, x_0) (используйте уравнение (4))\n",
        "    self.xt_coef = ...\n",
        "    self.x0_coef = ...\n",
        "    # ====\n",
        "\n",
        "ReverseDiffusionTemplate.get_coeffs = get_coeffs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQGIwF0IouBN"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54s0JjXf49pL"
      },
      "outputs": [],
      "source": [
        "class ReverseDiffusion(ReverseDiffusionTemplate):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.get_variances()\n",
        "        self.get_coeffs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzWK1Ig0ovoa"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 6 [1 балл]**\n",
        "\n",
        "Коэффициенты перед $\\mathbf{x}_t$ и $\\mathbf{x}_0$ Вы уже подсчитали, но теперь нужно разобраться с самим $\\mathbf{x}_0$. Далее Вам предлагается написать функцию `get_x0`, которой на вход подается зашумленное изображение `xt`, добавленный шум `eps`, а также момент времени `t`. Она должна возвращать `x0` - исходное изображение. Используйте уравнение (6)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQvq6Z9rk2O6"
      },
      "outputs": [],
      "source": [
        "def get_x0(self, xt, eps, t):\n",
        "    # ====\n",
        "    # 6. Ваш код\n",
        "    # Получите x_0 (используйте уравнение (6))\n",
        "    sqrt_alphas_cumprod = self.alphas_cumprod.sqrt()\n",
        "    x0 = ...\n",
        "    # ====\n",
        "    return x0\n",
        "\n",
        "ReverseDiffusion.get_x0 = get_x0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvKAnA4rpvzi"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU39KFxtpw-r"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 7 [1 балл]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bmLIK21qX4a"
      },
      "source": [
        "Наконец, можно реализовать метод подсчета тензоров математического ожидания и дисперсии в обратном диффузионном процессе. Далее Вы можете наблюдать функцию `get_mean_variance_reverse`. На вход она получает то же, что и `get_x0`, то есть зашумленное изображение `xt`, добавленный шум `eps`, а также момент времени `t`. Возвращать должна два `torch.tensor` - `mean` и `variance`. Используйте уравнения (4) и (5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gcsfZjXk7y7"
      },
      "outputs": [],
      "source": [
        "def get_mean_variance_reverse(self, xt, eps, t):\n",
        "    # ====\n",
        "    # 7. Ваш код\n",
        "    # Получите среднее и дисперсию распределения q(x_{t-1} | x_t, x_0) (используйте уравнения (4) и (5))\n",
        "    mean = ...\n",
        "    variance = ...\n",
        "    # ====\n",
        "    return mean, variance\n",
        "\n",
        "ReverseDiffusion.get_mean_variance = get_mean_variance_reverse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQGNLkLKrN6y"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnzf_zDyrTYc"
      },
      "source": [
        "Просим Вас прочитать внимательно следующий код. Функция `get_samples` возрвращает сэмпл из распределения обратного диффузионного процесса, используя все вышеопределенные Вами функции."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewr0lI-jlFi_"
      },
      "outputs": [],
      "source": [
        "def get_samples(self, xt, eps, t):\n",
        "    # Прочитайте этот код внимательно\n",
        "    mean, variance = self.get_mean_variance(xt=xt, eps=eps, t=t)\n",
        "    noise = torch.randn_like(xt, device=xt.device)\n",
        "\n",
        "    nonzero_mask = torch.ones_like(t)  # Чтобы не добавлять никакого шума при предсказании x0\n",
        "    nonzero_mask[t == 0] = 0\n",
        "    nonzero_mask = _extract_into_tensor(\n",
        "        nonzero_mask, torch.arange(nonzero_mask.shape[0]), xt.shape\n",
        "    )\n",
        "    nonzero_mask = nonzero_mask.to(xt.device)\n",
        "    sample = mean + nonzero_mask * variance.sqrt() * noise\n",
        "    return sample.float()\n",
        "\n",
        "ReverseDiffusion.get_samples = get_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qs7NoTZartx6"
      },
      "source": [
        "Далее протестируем весь написанный код, чтобы убедиться в правильности имплементации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:26.611265Z",
          "iopub.status.busy": "2024-04-26T07:27:26.610996Z",
          "iopub.status.idle": "2024-04-26T07:27:26.640292Z",
          "shell.execute_reply": "2024-04-26T07:27:26.639147Z",
          "shell.execute_reply.started": "2024-04-26T07:27:26.611240Z"
        },
        "id": "2kw_529KEDvJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Тестирование Вашего кода\n",
        "def test_reverse_diffusion():\n",
        "    rdiff = ReverseDiffusion(num_timesteps=100)\n",
        "    SHAPE = [2, 20]\n",
        "    xt = torch.ones(SHAPE)\n",
        "    eps = torch.ones(SHAPE)\n",
        "    t = torch.ones((2,)).long() * 5\n",
        "\n",
        "    x0 = rdiff.get_x0(xt=xt, eps=eps, t=t)\n",
        "    assert list(x0.shape) == SHAPE\n",
        "    assert np.allclose(x0.numpy(), np.ones(SHAPE) * 0.8260552)\n",
        "\n",
        "    mean, variance = rdiff.get_mean_variance(xt=xt, eps=eps, t=t)\n",
        "    assert list(mean.shape) == SHAPE\n",
        "    assert list(variance.shape) == SHAPE\n",
        "    assert np.allclose(mean.numpy(), np.ones(SHAPE) * 0.9467155)\n",
        "    assert np.allclose(variance.numpy(), np.ones(SHAPE) * 0.007709955)\n",
        "\n",
        "    x = rdiff.get_samples(xt, eps, t)\n",
        "    assert list(x.shape) == SHAPE\n",
        "    print('Отлично, Вы справились!')\n",
        "\n",
        "\n",
        "test_reverse_diffusion()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d2UR_JDEDvJ"
      },
      "source": [
        "#### Модель предсказания шума\n",
        "\n",
        "Нейронная сеть U-Net для предсказания шума, как было сказано, уже написана за Вас. Остается только импортировать ее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:26.641781Z",
          "iopub.status.busy": "2024-04-26T07:27:26.641454Z",
          "iopub.status.idle": "2024-04-26T07:27:40.273897Z",
          "shell.execute_reply": "2024-04-26T07:27:40.272544Z",
          "shell.execute_reply.started": "2024-04-26T07:27:26.641754Z"
        },
        "id": "_NQFmXO2AlN6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install -q -U denoising_diffusion_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:40.275809Z",
          "iopub.status.busy": "2024-04-26T07:27:40.275466Z",
          "iopub.status.idle": "2024-04-26T07:27:40.358156Z",
          "shell.execute_reply": "2024-04-26T07:27:40.357404Z",
          "shell.execute_reply.started": "2024-04-26T07:27:40.275778Z"
        },
        "id": "3q7NMeF4BDaK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from denoising_diffusion_pytorch import Unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kI8vGMuEDvJ"
      },
      "source": [
        "#### DDPM [2 балла]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEZ__C82KlzL"
      },
      "source": [
        "Вернемся к ELBO. Основная ее часть это\n",
        "$$\n",
        "    \\mathcal{L}_t = KL \\bigl(q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) || p(\\mathbf{x}_{t - 1} | \\mathbf{x}_t, \\boldsymbol{\\theta} )\\bigr).\n",
        "$$\n",
        "\n",
        "Как обсуждалось ранее, переходя к параметризации шума, можно получить следующее выражение:\n",
        "$$\n",
        "    \\mathcal{L}_t = \\mathbb{E}_{\\boldsymbol{\\epsilon}} \\left[ \\frac{\\beta_t^2}{2 \\tilde{\\beta_t} \\alpha_t (1 - \\bar{\\alpha}_t)} \\| \\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t) \\|^2 \\right].\n",
        "$$\n",
        "\n",
        "На практике этот лосс еще упрощается. А именно, мы опустим коэффиценты перед нормами и будем сэмплировать индекс $t$ на каждой итерации обучения.\n",
        "\n",
        "Окончательно, мы будем обучать нашу модель со следующим лоссом:\n",
        "$$\n",
        "\\text{loss} = \\mathbb{E}_{\\mathbf{x}_0, \\boldsymbol{\\epsilon}, t}\\bigg[ \\|\\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)\\|^2\\bigg],\n",
        "$$\n",
        "где $\\mathbf{x}_t = \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea5279S9EDvJ"
      },
      "source": [
        "Следующий класс имплементирует два метода:\n",
        "- `train_loss` - чтобы вычислять лосс на итерации обучения;\n",
        "- `sample` - чтобы сэмплировать из финальной модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP-exsJPsR7h"
      },
      "outputs": [],
      "source": [
        "class DDPM(nn.Module):\n",
        "    def __init__(self, num_timesteps: int, model: nn.Module):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_timesteps = num_timesteps\n",
        "\n",
        "        self.forward_diffusion = ForwardDiffusion(num_timesteps=num_timesteps)\n",
        "        self.reverse_diffusion = ReverseDiffusion(num_timesteps=num_timesteps)\n",
        "        self.model = model\n",
        "        self.shape = None\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea7kTKXksb1k"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 8 [1 балл]**\n",
        "\n",
        "От Вас требуется написать часть функции `sample`. На вход ей подается число сэмплов `num_samples`, которые будут сделаны из итоговой модели. Ваша часть состоит в том, чтобы получить $\\boldsymbol{\\epsilon}_{\\boldsymbol{\\theta}}(\\mathbf{x}_t, t)$ с помощью модели `self.model` (в нашем случае это U-Net), а затем сделать очередной шаг обратного процесса, сгенерировав сэмпл из соответствующего распределения. В этом Вам должна помочь функция `get_samples` у `self.reverse_diffusion`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWtrjLBHuD9s"
      },
      "outputs": [],
      "source": [
        "def sample(self, num_samples):\n",
        "    assert self.shape is not None\n",
        "    x = torch.randn((num_samples, *self.shape), device=self.device, dtype=torch.float32)\n",
        "    indices = list(range(self.num_timesteps))[::-1]\n",
        "\n",
        "    for i in tqdm(indices):\n",
        "        t = torch.tensor([i] * num_samples, device=x.device)\n",
        "        with torch.no_grad():\n",
        "            # ====\n",
        "            # 8. Ваш код\n",
        "            # 1) Получите epsilon из модели\n",
        "            eps = ...\n",
        "            # 2) Сгенерируйте сэмпл из обратной диффузии\n",
        "            x = ...\n",
        "            # ====\n",
        "    return x\n",
        "\n",
        "DDPM.sample = sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkAUsmmRuIU5"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIgOSm9kuJlb"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 9 [1 балл]**\n",
        "\n",
        "Настал черед `train_loss` - функции, которая получает на вход исходное изображение `x0`, а возвращает `loss`, подсчитанный с помощью `F.mse_loss`. Вам необходимо с помощью `self.forward_diffusion` сгенерировать сэмплы `xt` (см. метод `get_samples`), а затем получить предсказание `eps` добавленного шума с помощью `self.model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:40.359587Z",
          "iopub.status.busy": "2024-04-26T07:27:40.359287Z",
          "iopub.status.idle": "2024-04-26T07:27:40.372861Z",
          "shell.execute_reply": "2024-04-26T07:27:40.371572Z",
          "shell.execute_reply.started": "2024-04-26T07:27:40.359562Z"
        },
        "id": "U7VNG-hJEDvJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_loss(self, x0):\n",
        "    if self.shape is None:\n",
        "        self.shape = list(x0.shape)[1:]\n",
        "    t = torch.randint(0, self.num_timesteps, size=(x0.size(0),), device=x0.device)\n",
        "    noise = torch.randn_like(x0)\n",
        "\n",
        "    # ====\n",
        "    # 9. Ваш код\n",
        "    # 1) Получите x_t\n",
        "    xt = ...\n",
        "    # 2) Получите epsilon из модели\n",
        "    eps = ...\n",
        "    # ====\n",
        "    loss = F.mse_loss(eps, noise)\n",
        "    return loss\n",
        "\n",
        "DDPM.train_loss = train_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xw6vueDnTt7C"
      },
      "source": [
        "### Обучение [1 балл]\n",
        "\n",
        "Сейчас мы готовы обучить нашу модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e43ionGv1Z3"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Задание 10 [1 балл]**\n",
        "\n",
        "В процессе обучения мы, как обсуждалось ранее, пропускаем через энкодер вариационного автокодировщика `vae` исходное изображение. Энкодер выдает нам распределение в скрытом пространстве `latent_dist`. Далее из этого распределения мы сэмплируем `z`. И вот этот `z` уже подается на вход DDPM, которая и возвращает нам loss. Вам нужно реализовать часть процесса обучения - функцию `get_latent`, которая реализует получение распределения в скрытом пространстве и сэмплирование."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05U0yi6Yw-Gg"
      },
      "outputs": [],
      "source": [
        "def get_latent(vae, x):\n",
        "    # ====\n",
        "    # 10. Ваш код\n",
        "    # 1) Получите распределение в латентном пространстве VQ-VAE, подав в него x\n",
        "    latent_dist = ...\n",
        "    # 2) Сгенерируйте сэмпл z из этого распределения\n",
        "    z = ...\n",
        "    return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBByrrJdxUn6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T07:27:40.374300Z",
          "iopub.status.busy": "2024-04-26T07:27:40.374014Z",
          "iopub.status.idle": "2024-04-26T07:27:40.389338Z",
          "shell.execute_reply": "2024-04-26T07:27:40.388496Z",
          "shell.execute_reply.started": "2024-04-26T07:27:40.374276Z"
        },
        "id": "tipqaz9zEDvK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "    vae: AutoencoderKL,\n",
        "    ddpm: DDPM,\n",
        "    dataloader: data.DataLoader,\n",
        "    lr: float,\n",
        "    weight_decay: float,\n",
        "    steps: int,\n",
        "    use_cuda: bool,\n",
        "    log_every: int = 500\n",
        "):\n",
        "\n",
        "    def _anneal_lr(step: int):\n",
        "        frac_done = step / steps\n",
        "        current_lr = lr * (1 - frac_done)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group[\"lr\"] = current_lr\n",
        "\n",
        "    if USE_CUDA:\n",
        "        vae = vae.cuda()\n",
        "        ddpm = ddpm.cuda()\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        ddpm.model.parameters(), lr=lr, weight_decay=weight_decay\n",
        "    )\n",
        "    step = 0\n",
        "    curr_loss_gauss = 0.0\n",
        "    curr_count = 0\n",
        "    optimizer.zero_grad()\n",
        "    data_iter = iter(dataloader)\n",
        "    while step < steps:\n",
        "        try:\n",
        "            x = next(data_iter)['images']\n",
        "        except StopIteration:\n",
        "            data_iter = iter(dataloader)\n",
        "            x = next(data_iter)['images']\n",
        "\n",
        "        if USE_CUDA:\n",
        "            x = x.cuda()\n",
        "\n",
        "        z = get_latent(vae, x)\n",
        "\n",
        "        loss = ddpm.train_loss(z)\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        _anneal_lr(step)\n",
        "\n",
        "        curr_count += len(z)\n",
        "        curr_loss_gauss += loss.item() * len(z)\n",
        "\n",
        "        if (step + 1) % log_every == 0:\n",
        "            gloss = np.around(curr_loss_gauss / curr_count, 4)\n",
        "            print(f\"Step {(step + 1)}/{steps} Loss: {gloss}\")\n",
        "            curr_count = 0\n",
        "            curr_loss_gauss = 0.0\n",
        "\n",
        "        step += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoZCB6_Axcg0"
      },
      "source": [
        "---\n",
        "\n",
        "##### **Подбор параметров обучения**\n",
        "\n",
        "Последнее, что Вы должны сделать в этом домашнем задании - поэкспериментировать с параметрами обучения получившейся нейронной сети. В качестве начального приближения можно использовать следующий набор:\n",
        "- `BATCH_SIZE = 16`\n",
        "- `LR = 1e-3`\n",
        "- `WEIGHT_DECAY = 1e-5`\n",
        "- `STEPS = 10000`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_YazvF8yBbp"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "T = 1000\n",
        "# ====\n",
        "# Ваш код\n",
        "# Подберите эти параметры\n",
        "BATCH_SIZE = ...\n",
        "LR = ...\n",
        "WEIGHT_DECAY = ...\n",
        "STEPS = ...\n",
        "# ====\n",
        "\n",
        "dataloader = data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "vae = AutoencoderKL.from_pretrained(\"CompVis/stable-diffusion-v1-4\", subfolder=\"vae\")\n",
        "unet = Unet(dim=64,\n",
        "            dim_mults=(1, 2, 4, 8),\n",
        "            channels=vae.config.latent_channels)\n",
        "ddpm = DDPM(num_timesteps=T, model=unet)\n",
        "\n",
        "train_model(\n",
        "    vae=vae,\n",
        "    ddpm=ddpm,\n",
        "    dataloader=dataloader,\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY,\n",
        "    steps=STEPS,\n",
        "    use_cuda=USE_CUDA,\n",
        "    log_every=500\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9qzlWGryCbk"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm-l02fEcYvO"
      },
      "source": [
        "Теперь можно посмотреть, какие изображения способна генерировать наша модель. Для этого необходимо создать несколько сэмплов в латентном пространстве с помощью написанной нами модели DDPM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T09:37:18.177329Z",
          "iopub.status.busy": "2024-04-26T09:37:18.176890Z",
          "iopub.status.idle": "2024-04-26T09:37:39.506507Z",
          "shell.execute_reply": "2024-04-26T09:37:39.505573Z",
          "shell.execute_reply.started": "2024-04-26T09:37:18.177293Z"
        },
        "id": "LyZHZNEDcPoE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "num_samples = 4\n",
        "latent_samples = ddpm.sample(num_samples)\n",
        "latent_samples.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rkn5KyyIcsi1"
      },
      "source": [
        "Далее пропустим их через декодер нашего VQ-VAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T09:37:39.508015Z",
          "iopub.status.busy": "2024-04-26T09:37:39.507712Z",
          "iopub.status.idle": "2024-04-26T09:37:39.643002Z",
          "shell.execute_reply": "2024-04-26T09:37:39.642235Z",
          "shell.execute_reply.started": "2024-04-26T09:37:39.507988Z"
        },
        "id": "fZLVkTyCconz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "samples = vae.decode(latent_samples).sample.detach()\n",
        "samples.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-3w9nA0c1VJ"
      },
      "source": [
        "Остается только вывести полученные изображения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-26T09:37:39.644161Z",
          "iopub.status.busy": "2024-04-26T09:37:39.643894Z",
          "iopub.status.idle": "2024-04-26T09:37:41.018925Z",
          "shell.execute_reply": "2024-04-26T09:37:41.018027Z",
          "shell.execute_reply.started": "2024-04-26T09:37:39.644137Z"
        },
        "id": "cFCKtYyuWTyr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "images = [np.uint8(sample.permute((1, 2, 0)).cpu().numpy().clip(0, 1) * 255) for sample in samples]\n",
        "images = [Image.fromarray(image, mode='RGB') for image in images]\n",
        "\n",
        "fig, axs = plt.subplots(1, 4, figsize=(20, 4))\n",
        "\n",
        "for i, image in enumerate(images):\n",
        "    axs[i].imshow(image)\n",
        "    axs[i].set_axis_off()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results.png\", bbox_inches=\"tight\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx6dcwCfzbI2"
      },
      "source": [
        "Ниже Вы можете видеть изображения, которые получаются при обучении модели в течение ~2 часов на GPU T4.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=16z0E10sIDPeT29vC3eW-8Q2jxYAqGmOL\"/>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
